\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{Chatterjee2005}
\@writefile{toc}{\contentsline {section}{\numberline {1}Acknowledgements}{4}{section.1}}
\@writefile{toc}{\contentsline {paragraph}{}{4}{section*.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Notation}{6}{section.2}}
\citation{Touchette20091}
\citation{LargeDeviations}
\citation{varadhan2008}
\@writefile{toc}{\contentsline {section}{\numberline {3}Introduction}{7}{section.3}}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.4}}
\citation{Kontorovich_Metric}
\citation{McDonald_TimeSeries}
\citation{tao2012topics}
\citation{Tropp_FoCM_2011}
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.5}}
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.6}}
\@writefile{toc}{\contentsline {paragraph}{}{8}{section*.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}What does the word Application mean?}{8}{subsection.3.1}}
\citation{Milman}
\citation{JordanLipschitz}
\citation{McDonald_TimeSeries}
\citation{SLT_Lugosi_Bocheron}
\citation{Ledoux_lecture_notes}
\citation{McDiarmid_1997}
\citation{mcquarrie1998regression}
\citation{romer2011advanced}
\@writefile{toc}{\contentsline {paragraph}{}{9}{section*.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}What is in this thesis?}{9}{subsection.3.2}}
\@writefile{toc}{\contentsline {paragraph}{}{9}{section*.9}}
\@writefile{toc}{\contentsline {section}{\numberline {4}What are other examples of Concentration of Measure?}{10}{section.4}}
\newlabel{sec:ConcMeasure}{{4}{10}{What are other examples of Concentration of Measure?\relax }{section.4}{}}
\newlabel{eq:1}{{1}{10}{What are other examples of Concentration of Measure?\relax }{equation.4.1}{}}
\citation{cover2006elements}
\newlabel{eq:2}{{2}{12}{What are other examples of Concentration of Measure?\relax }{equation.4.2}{}}
\citation{marton1996measure}
\newlabel{eq:3}{{4}{13}{What are other examples of Concentration of Measure?\relax }{equation.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Probabilistic viewpoint}{14}{subsection.4.1}}
\newlabel{eq:4}{{5}{14}{Probabilistic viewpoint\relax }{equation.4.5}{}}
\citation{bobkov1999exponential}
\citation{Raginsky_ConcMeasure}
\citation{Ledoux_lecture_notes}
\citation{TalagrandInequality}
\citation{Ledoux}
\citation{Ledoux_lecture_notes}
\citation{Ledoux_lecture_notes}
\citation{Lugosi}
\citation{Ledoux_lecture_notes}
\citation{barvinok2005math}
\citation{cover2006elements}
\newlabel{eq:5}{{6}{16}{Probabilistic viewpoint\relax }{equation.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Some further classic examples}{16}{subsection.4.2}}
\citation{McDiarmid_tutorial}
\citation{cover2006elements}
\citation{Raginsky_ConcMeasure}
\citation{boucheron2013concentration}
\citation{Ledoux_lecture_notes}
\citation{Lugosi}
\citation{SLT_Lugosi_Bocheron}
\citation{Chatterjee2005}
\citation{2009arXiv0906.1034C}
\newlabel{eq:6}{{7}{17}{Some further classic examples\relax }{equation.4.7}{}}
\citation{McDonald_TimeSeries}
\citation{vapnik2000nature}
\citation{dudley1999uniform}
\citation{massart}
\citation{boucheron2013concentration}
\citation{Pollard1990}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}What is Empirical Process theory}{18}{subsection.4.3}}
\newlabel{sec:SLT}{{4.3}{18}{What is Empirical Process theory\relax }{subsection.4.3}{}}
\@writefile{toc}{\contentsline {paragraph}{}{18}{section*.10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}So why should we care about empirical process theory?}{19}{subsection.4.4}}
\newlabel{sec:MachineLearning}{{4.4}{19}{So why should we care about empirical process theory?\relax }{subsection.4.4}{}}
\@writefile{toc}{\contentsline {paragraph}{}{19}{section*.11}}
\citation{vapnik2000nature}
\citation{Hoeffding}
\citation{Azuma}
\@writefile{toc}{\contentsline {paragraph}{}{20}{section*.12}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Basic concentration inequalities via the martingale approach}{20}{section.5}}
\newlabel{section: Basic Concentration Inequalities}{{5}{20}{Basic concentration inequalities via the martingale approach\relax }{section.5}{}}
\newlabel{sec:ConcInequalities}{{5}{20}{Basic concentration inequalities via the martingale approach\relax }{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}The Azuma-Hoeffding inequality}{21}{subsection.5.1}}
\newlabel{subsection: Azuma's inequality}{{5.1}{21}{The Azuma-Hoeffding inequality\relax }{subsection.5.1}{}}
\newlabel{eq: Azuma's concentration inequality - general case}{{8}{21}{\relax }{equation.5.8}{}}
\newlabel{theorem: Azuma's concentration inequality}{{5.1}{21}{\relax }{equation.5.8}{}}
\newlabel{eq: union of disjoint events}{{9}{21}{The Azuma-Hoeffding inequality\relax }{equation.5.9}{}}
\newlabel{eq: Chernoff's inequality}{{10}{22}{The Azuma-Hoeffding inequality\relax }{equation.5.10}{}}
\newlabel{eq: smoothing theorem}{{11}{22}{The Azuma-Hoeffding inequality\relax }{equation.5.11}{}}
\newlabel{eq: cosine hyperbolic}{{12}{22}{The Azuma-Hoeffding inequality\relax }{equation.5.12}{}}
\citation{McDiarmid_tutorial}
\newlabel{eq: one-sided Azuma's inequality}{{13}{23}{The Azuma-Hoeffding inequality\relax }{equation.5.13}{}}
\newlabel{eq: concentration inequality for a martingale-difference sequence (McDiarmid's tutorial)}{{14}{24}{\relax }{equation.5.14}{}}
\newlabel{eq: concentration inequality for a martingale sequence (McDiarmid's tutorial)}{{15}{24}{\relax }{equation.5.15}{}}
\newlabel{eq: Azuma's inequality for example1}{{16}{24}{\relax }{equation.5.16}{}}
\citation{Bernstein}
\citation{Ledoux}
\citation{boucheron2013concentration}
\newlabel{CLT1 - i.i.d. RVs}{{17}{25}{\relax }{equation.5.17}{}}
\newlabel{eq: Q function}{{18}{25}{\relax }{equation.5.18}{}}
\newlabel{eq: upper and lower bounds for the Q function}{{19}{25}{\relax }{equation.5.19}{}}
\newlabel{example1}{{5.3}{25}{\relax }{equation.5.19}{}}
\newlabel{eq:CLT2 - i.i.d. RVs}{{20}{25}{\relax }{equation.5.20}{}}
\citation{McDiarmid_1997}
\citation{McDiarmid_tutorial}
\citation{Azuma}
\newlabel{example2}{{5.4}{26}{\relax }{equation.5.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}McDiarmid's inequality}{26}{subsection.5.2}}
\newlabel{subsection: McDiarmid's inequality}{{5.2}{26}{McDiarmid's inequality\relax }{subsection.5.2}{}}
\newlabel{eq: assumption on the variation of g}{{21}{26}{\relax }{equation.5.21}{}}
\newlabel{eq: McDiarmid's inequality}{{22}{26}{\relax }{equation.5.22}{}}
\newlabel{theorem: McDiarmid's inequality}{{5.5}{26}{\relax }{equation.5.22}{}}
\newlabel{eq: martingale difference}{{23}{27}{McDiarmid's inequality\relax }{equation.5.23}{}}
\newlabel{eq: independence}{{25}{28}{McDiarmid's inequality\relax }{equation.5.25}{}}
\newlabel{eq: bound on the variation of g w.r.t. k-th coordinate}{{26}{28}{McDiarmid's inequality\relax }{equation.5.26}{}}
\newlabel{eq: upper bound on the conditional expectation for McDiadmid's inequality}{{27}{29}{McDiarmid's inequality\relax }{equation.5.27}{}}
\newlabel{eq: H_k}{{28}{29}{McDiarmid's inequality\relax }{equation.5.28}{}}
\newlabel{eq: upper bound on H_k used for Hoeffding inequality}{{29}{29}{McDiarmid's inequality\relax }{equation.5.29}{}}
\citation{Hoeffding}
\citation{KS_1998}
\newlabel{eq: one-sided McDiarmid's inequality}{{32}{30}{McDiarmid's inequality\relax }{equation.5.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Hoeffding's inequality, and its improved version (the Kearns-Saul inequality)}{30}{subsection.5.3}}
\citation{SLT_Lugosi_Bocheron}
\citation{vapnik2000nature}
\citation{Bartlett}
\citation{hastie2001elements}
\citation{hastie2001elements}
\newlabel{eq: Hoeffding inequality}{{33}{31}{Hoeffding\relax }{equation.5.33}{}}
\newlabel{theorem: Hoeffding inequality}{{5.8}{31}{Hoeffding\relax }{equation.5.33}{}}
\newlabel{thm:hoeffding}{{5.8}{31}{Hoeffding\relax }{equation.5.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Statistical Learning Theory}{31}{section.6}}
\newlabel{sec:Applications}{{6}{31}{Statistical Learning Theory\relax }{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Notations from learning theory}{31}{subsection.6.1}}
\newlabel{subsec:LearningTheory}{{6.1}{31}{Notations from learning theory\relax }{subsection.6.1}{}}
\@writefile{toc}{\contentsline {paragraph}{What is the formal defintion of learning?}{31}{section*.13}}
\citation{mcquarrie1998regression}
\citation{McDonald_TimeSeries}
\citation{romer2011advanced}
\citation{scikit-learn}
\citation{hastie2001elements}
\citation{SLT_Lugosi_Bocheron}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Classification}{32}{subsubsection.6.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.2}Regression}{32}{subsubsection.6.1.2}}
\citation{mcquarrie1998regression}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.3}Density Estimation}{33}{subsubsection.6.1.3}}
\newlabel{fig:Linear Regression with Pseudo-Randomly generated Data}{{6.1}{34}{\relax }{equation.6.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Linear regression example with Pseudo-Randomly generated data}}{34}{figure.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}The Traditional Setup}{34}{subsection.6.2}}
\newlabel{def:risk}{{6.3}{35}{Risk or generalization error\relax }{theorem.6.3}{}}
\@writefile{toc}{\contentsline {paragraph}{}{35}{section*.14}}
\@writefile{toc}{\contentsline {paragraph}{}{36}{section*.15}}
\newlabel{def:Empirical_Risk_Minimizer}{{6.4}{36}{\relax }{theorem.6.4}{}}
\newlabel{equation:3.6}{{42}{36}{\relax }{equation.6.42}{}}
\@writefile{toc}{\contentsline {paragraph}{}{36}{section*.16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Concentration}{37}{subsection.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Contol by Counting}{37}{subsection.6.4}}
\citation{KS_1998}
\citation{bousquet2002stability}
\citation{vapnik2000nature}
\citation{Pollard1990}
\citation{Bartlett}
\citation{vapnik2000nature}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Capacity}{38}{subsection.6.5}}
\newlabel{sec:capacity}{{6.5}{38}{Capacity\relax }{subsection.6.5}{}}
\newlabel{eq:union-bound}{{46}{38}{Capacity\relax }{equation.6.46}{}}
\citation{VapnikChervonenkis1971}
\citation{VapnikChervonenkis1971}
\newlabel{thm:vapnik}{{6.8}{39}{\cite {VapnikChervonenkis1971}\relax }{theorem.6.8}{}}
\newlabel{eq:vcbound}{{51}{39}{\cite {VapnikChervonenkis1971}\relax }{equation.6.51}{}}
\citation{CristianiniShawe-Taylor2000}
\newlabel{cor:vapnik}{{6.9}{40}{\relax }{theorem.6.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Illustration of VC dimension for some function classes.}}{40}{figure.2}}
\newlabel{fig:Illustration of VC Dimensions}{{2}{40}{Illustration of VC dimension for some function classes}{figure.2}{}}
\citation{Gine1984}
\citation{Talagrand95}
\citation{TalagrandInequality}
\@writefile{toc}{\contentsline {section}{\numberline {7}Rademacher Processes}{41}{section.7}}
\newlabel{sec:Rademacher}{{7}{41}{Rademacher Processes\relax }{section.7}{}}
\@writefile{toc}{\contentsline {paragraph}{}{41}{section*.17}}
\citation{dudley1999uniform}
\citation{Ledoux}
\citation{SLT_Lugosi_Bocheron}
\citation{Bartlett}
\citation{Pandas}
\@writefile{toc}{\contentsline {section}{\numberline {8}Time series}{43}{section.8}}
\newlabel{sec:dependence}{{8}{43}{Time series\relax }{section.8}{}}
\citation{AdamsNobel2010}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Time Series example showing the changes in Beef consumption over the 20th Century in the US}}{44}{figure.3}}
\newlabel{fig:Time Series of USDA Meat Data}{{3}{44}{Time Series example showing the changes in Beef consumption over the 20th Century in the US\relax }{figure.3}{}}
\newlabel{def:stationary}{{8.2}{44}{Stationarity\relax }{theorem.8.2}{}}
\citation{Bradley2005}
\citation{Mokkadem1988}
\citation{CarrascoChen2002}
\citation{doukhan1994mixing}
\newlabel{defn:beta-mix}{{8.3}{45}{$\beta $-Mixing\relax }{theorem.8.3}{}}
\newlabel{eq:three}{{54}{45}{$\beta $-Mixing\relax }{equation.8.54}{}}
\citation{McDonald_TimeSeries}
\@writefile{toc}{\contentsline {section}{\numberline {9}Risk bounds}{46}{section.9}}
\newlabel{sec:risk-bounds}{{9}{46}{Risk bounds\relax }{section.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Setup and assumptions}{46}{subsection.9.1}}
\newlabel{sec:setup-assumptions}{{9.1}{46}{Setup and assumptions\relax }{subsection.9.1}{}}
\newlabel{ass:A}{{2}{46}{\relax }{assumption.2}{}}
\citation{DeJongDave2007}
\citation{DejongDharmarajan2009}
\citation{DeJongDave2007}
\newlabel{ass:B}{{3}{47}{\relax }{assumption.3}{}}
\citation{CorlessGonnet1996}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Fixed memory}{48}{subsection.9.2}}
\newlabel{sec:fixed-memory}{{9.2}{48}{Fixed memory\relax }{subsection.9.2}{}}
\newlabel{thm:bound1}{{9.3}{48}{\relax }{theorem.9.3}{}}
\newlabel{eq:bound1}{{58}{48}{\relax }{equation.9.58}{}}
\newlabel{eq:worsebound}{{59}{48}{Fixed memory\relax }{equation.9.59}{}}
\newlabel{cor:bound1}{{9.4}{49}{\relax }{theorem.9.4}{}}
\newlabel{eq:bound-with-known-vc}{{61}{49}{\relax }{equation.9.61}{}}
\newlabel{eq:bound-magnitude}{{62}{49}{\relax }{equation.9.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Visualizing the tradeoff between confidence ($\epsilon $, $y$-axis) and effective data ($\mu $, $x$-axis). The black curve indicates the region where the bound becomes trivial. Below this line, the probability is bounded by 1. Darker colors indicate lower probability of the ``bad'' event --- that the difference in risks exceeds $\epsilon $. The colors correspond to the natural logarithm of the bound on this probability.}}{50}{figure.4}}
\newlabel{fig:risk}{{4}{50}{Visualizing the tradeoff between confidence ($\epsilon $, $y$-axis) and effective data ($\mu $, $x$-axis). The black curve indicates the region where the bound becomes trivial. Below this line, the probability is bounded by 1. Darker colors indicate lower probability of the ``bad'' event --- that the difference in risks exceeds $\epsilon $. The colors correspond to the natural logarithm of the bound on this probability}{figure.4}{}}
\citation{Yu1994}
\citation{CortesMansour2010}
\newlabel{eq:almost-finished-bound}{{71}{52}{Fixed memory\relax }{equation.9.71}{}}
\citation{Shalizi2009}
\citation{McDonald_TimeSeries}
\citation{vapnik2000nature}
\citation{Berend_Kontorovich_missing_mass_2012}
\citation{Kontorovich_Metric}
\citation{McDonald_TimeSeries}
\citation{Bradley2005}
\citation{mcquarrie1998regression}
\citation{SLT_Lugosi_Bocheron}
\citation{boucheron2013concentration}
\citation{massart}
\citation{Bartlett}
\citation{hastie2001elements}
\citation{HausslerBound1989}
\citation{DudleyBound}
\newlabel{thm:vcd-ar}{{9.5}{53}{\relax }{theorem.9.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Discussion}{53}{section.10}}
\newlabel{sec:Discussion}{{10}{53}{Discussion\relax }{section.10}{}}
\citation{massart}
\citation{TalagrandInequality}
\citation{catoni2004statistical}
\citation{Raginsky_ConcMeasure}
\@writefile{toc}{\contentsline {paragraph}{}{54}{section*.18}}
\citation{bergstra+al:2010-scipy}
\citation{scikit-learn}
\citation{hastie2001elements}
\citation{McDonald_TimeSeries}
\citation{Yu1994}
\citation{CortesMansour2010}
\@writefile{toc}{\contentsline {section}{\numberline {A}Machine Learning - Computational Techniques}{55}{appendix.A}}
\@writefile{toc}{\contentsline {paragraph}{}{55}{section*.19}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Auxiliary results}{55}{appendix.B}}
\newlabel{sec:lemmas}{{B}{55}{Auxiliary results\relax }{appendix.B}{}}
\newlabel{lem:yu}{{B.1}{55}{Lemma 4.1 in \cite {Yu1994}\relax }{theorem.B.1}{}}
\newlabel{lem:vapnik}{{B.2}{55}{Theorem 7 in \cite {CortesMansour2010}\relax }{theorem.B.2}{}}
\citation{vapnik2000nature}
\bibstyle{plain}
\bibdata{bib}
\bibcite{Pandas}{1}
\bibcite{AdamsNobel2010}{2}
\bibcite{Azuma}{3}
\bibcite{Bartlett}{4}
\bibcite{barvinok2005math}{5}
\bibcite{Berend_Kontorovich_missing_mass_2012}{6}
\@writefile{toc}{\contentsline {section}{\numberline {C}Proofs of selected results}{56}{appendix.C}}
\newlabel{sec:proofs-results-srefs}{{C}{56}{Proofs of selected results\relax }{appendix.C}{}}
\bibcite{bergstra+al:2010-scipy}{7}
\bibcite{Bernstein}{8}
\bibcite{bobkov1999exponential}{9}
\bibcite{boucheron2013concentration}{10}
\bibcite{SLT_Lugosi_Bocheron}{11}
\bibcite{bousquet2002stability}{12}
\bibcite{Bradley2005}{13}
\bibcite{CarrascoChen2002}{14}
\bibcite{catoni2004statistical}{15}
\bibcite{Chatterjee2005}{16}
\bibcite{2009arXiv0906.1034C}{17}
\bibcite{CorlessGonnet1996}{18}
\bibcite{CortesMansour2010}{19}
\bibcite{cover2006elements}{20}
\bibcite{CristianiniShawe-Taylor2000}{21}
\bibcite{DejongDharmarajan2009}{22}
\bibcite{DeJongDave2007}{23}
\bibcite{doukhan1994mixing}{24}
\bibcite{DudleyBound}{25}
\bibcite{dudley1999uniform}{26}
\bibcite{HausslerBound1989}{27}
\bibcite{Gine1984}{28}
\bibcite{hastie2001elements}{29}
\bibcite{Hoeffding}{30}
\bibcite{JordanLipschitz}{31}
\bibcite{KS_1998}{32}
\bibcite{Kontorovich_Metric}{33}
\bibcite{Ledoux_lecture_notes}{34}
\bibcite{Lugosi}{35}
\bibcite{marton1996measure}{36}
\bibcite{McDiarmid_1997}{37}
\bibcite{McDiarmid_tutorial}{38}
\bibcite{McDonald_TimeSeries}{39}
\bibcite{mcquarrie1998regression}{40}
\bibcite{Milman}{41}
\bibcite{Ledoux}{42}
\bibcite{Mokkadem1988}{43}
\bibcite{scikit-learn}{44}
\bibcite{massart}{45}
\bibcite{Pollard1990}{46}
\bibcite{Raginsky_ConcMeasure}{47}
\bibcite{romer2011advanced}{48}
\bibcite{Shalizi2009}{49}
\bibcite{Talagrand95}{50}
\bibcite{TalagrandInequality}{51}
\bibcite{tao2012topics}{52}
\bibcite{Touchette20091}{53}
\bibcite{Tropp_FoCM_2011}{54}
\bibcite{vapnik2000nature}{55}
\bibcite{VapnikChervonenkis1971}{56}
\bibcite{varadhan2008}{57}
\bibcite{Yu1994}{58}
\bibcite{LargeDeviations}{59}
